"""
í”„ë¡œë•ì…˜ ë¡œê·¸ vs ë°±í…ŒìŠ¤íŠ¸ ì‹ í˜¸ ë¹„êµ (Historical)

ëª©ì : ì¼ì£¼ì¼ ì „ í”„ë¡œë•ì…˜ ë¡œê·¸ì˜ ì‹ í˜¸ë¥¼ ë°±í…ŒìŠ¤íŠ¸ë¡œ ì¬í˜„í•˜ì—¬ ë¹„êµ

Date: 2025-11-03
"""

import sys
from pathlib import Path
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import pickle
import joblib
import yaml

# Add project root to path
project_root = Path(__file__).resolve().parents[2]
sys.path.insert(0, str(project_root))

from src.api.bingx_client import BingXClient
from scripts.production.production_features_v1 import calculate_all_features_enhanced_v2

def load_models():
    """Load production models"""
    models_dir = project_root / "models"

    # Load LONG entry model
    long_entry_path = models_dir / "xgboost_long_entry_enhanced_20251024_012445.pkl"
    with open(long_entry_path, 'rb') as f:
        long_entry_model = pickle.load(f)

    # Load LONG entry scaler
    long_entry_scaler_path = models_dir / "xgboost_long_entry_enhanced_20251024_012445_scaler.pkl"
    long_entry_scaler = joblib.load(long_entry_scaler_path)

    # Load LONG entry features
    long_entry_features_path = models_dir / "xgboost_long_entry_enhanced_20251024_012445_features.txt"
    with open(long_entry_features_path, 'r') as f:
        long_entry_features = [line.strip() for line in f.readlines()]

    # Load SHORT entry model
    short_entry_path = models_dir / "xgboost_short_entry_enhanced_20251024_012445.pkl"
    with open(short_entry_path, 'rb') as f:
        short_entry_model = pickle.load(f)

    # Load SHORT entry scaler
    short_entry_scaler_path = models_dir / "xgboost_short_entry_enhanced_20251024_012445_scaler.pkl"
    short_entry_scaler = joblib.load(short_entry_scaler_path)

    # Load SHORT entry features
    short_entry_features_path = models_dir / "xgboost_short_entry_enhanced_20251024_012445_features.txt"
    with open(short_entry_features_path, 'r') as f:
        short_entry_features = [line.strip() for line in f.readlines()]

    return {
        'long_entry': {
            'model': long_entry_model,
            'scaler': long_entry_scaler,
            'features': long_entry_features
        },
        'short_entry': {
            'model': short_entry_model,
            'scaler': short_entry_scaler,
            'features': short_entry_features
        }
    }

def get_backtest_signals(df, models):
    """Calculate backtest signals for historical data"""

    # Calculate features (same as production)
    print("\nğŸ”§ Calculating features (same method as production)...")
    df_features = calculate_all_features_enhanced_v2(df.copy(), phase='phase1')

    print(f"   Features calculated: {len(df_features.columns)} columns")
    print(f"   Rows: {len(df)} â†’ {len(df_features)} (lost {len(df) - len(df_features)} due to lookback)")

    # Get latest candle features
    latest_features = df_features.iloc[-1]

    # LONG signal
    long_features = models['long_entry']['features']
    long_feat_df = pd.DataFrame([latest_features[long_features].values], columns=long_features)
    long_feat_scaled = models['long_entry']['scaler'].transform(long_feat_df)
    long_prob = models['long_entry']['model'].predict_proba(long_feat_scaled)[0, 1]

    # SHORT signal
    short_features = models['short_entry']['features']
    short_feat_df = pd.DataFrame([latest_features[short_features].values], columns=short_features)
    short_feat_scaled = models['short_entry']['scaler'].transform(short_feat_df)
    short_prob = models['short_entry']['model'].predict_proba(short_feat_scaled)[0, 1]

    return {
        'long_prob': long_prob,
        'short_prob': short_prob,
        'features': latest_features,
        'timestamp': df_features.iloc[-1]['timestamp'] if 'timestamp' in df_features.columns else df.iloc[-1]['timestamp']
    }

def parse_production_log(log_file, target_time_kst):
    """Parse production log to extract signals at specific time"""

    print(f"\nğŸ“‹ í”„ë¡œë•ì…˜ ë¡œê·¸ íŒŒì‹± ì¤‘...")
    print(f"   íŒŒì¼: {log_file.name}")
    print(f"   ëª©í‘œ ì‹œê°„ (KST): {target_time_kst.strftime('%Y-%m-%d %H:%M')}")

    with open(log_file, 'r', encoding='utf-8') as f:
        lines = f.readlines()

    # Find the line matching target time
    target_str = target_time_kst.strftime('%H:%M:00 KST')

    for line in lines:
        if target_str in line and 'LONG:' in line and 'SHORT:' in line:
            # Parse: [Candle 21:00:00 KST] Price: $114,514.7 | Balance: $4,376.87 | LONG: 0.5876 | SHORT: 0.5968
            parts = line.split('|')

            # Extract price
            price_str = [p for p in parts if 'Price:' in p][0]
            price = float(price_str.split('$')[1].replace(',', '').strip())

            # Extract LONG
            long_str = [p for p in parts if 'LONG:' in p][0]
            long_prob = float(long_str.split(':')[1].strip())

            # Extract SHORT
            short_str = [p for p in parts if 'SHORT:' in p][0]
            short_prob = float(short_str.split(':')[1].strip())

            print(f"   âœ… ë¡œê·¸ ë°œê²¬!")
            print(f"      Price: ${price:,.1f}")
            print(f"      LONG: {long_prob:.4f} ({long_prob*100:.2f}%)")
            print(f"      SHORT: {short_prob:.4f} ({short_prob*100:.2f}%)")

            return {
                'timestamp': target_time_kst,
                'price': price,
                'long_prob': long_prob,
                'short_prob': short_prob
            }

    print(f"   âŒ í•´ë‹¹ ì‹œê°„ ë¡œê·¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
    return None

def main():
    print("=" * 80)
    print("Historical ë°±í…ŒìŠ¤íŠ¸ vs í”„ë¡œë•ì…˜ ì‹ í˜¸ ë¹„êµ ë¶„ì„")
    print("=" * 80)

    # Target time: Oct 28, 21:00 KST (12:00 UTC)
    target_time_kst = datetime(2025, 10, 28, 21, 0, 0)
    target_time_utc = target_time_kst - timedelta(hours=9)

    print(f"\nğŸ¯ ë¹„êµ ì‹œì :")
    print(f"   KST: {target_time_kst.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"   UTC: {target_time_utc.strftime('%Y-%m-%d %H:%M:%S')}")

    # Parse production log
    log_file = project_root / "logs" / "opportunity_gating_bot_4x_20251028.log"
    production_signal = parse_production_log(log_file, target_time_kst)

    if production_signal is None:
        print("\nâŒ í”„ë¡œë•ì…˜ ë¡œê·¸ì—ì„œ í•´ë‹¹ ì‹œê°„ ì‹ í˜¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # Load models
    print("\nğŸ”§ ëª¨ë¸ ë¡œë”©...")
    models = load_models()
    print(f"   âœ… LONG Entry: {len(models['long_entry']['features'])} features")
    print(f"   âœ… SHORT Entry: {len(models['short_entry']['features'])} features")

    # Load API credentials
    config_path = project_root / "config" / "api_keys.yaml"
    with open(config_path, 'r') as f:
        api_config = yaml.safe_load(f)

    # Get historical market data
    print("\nğŸ“¡ Historical ì‹œì¥ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°...")
    print(f"   ëª©í‘œ: {target_time_utc.strftime('%Y-%m-%d %H:%M')} UTC ê¹Œì§€ì˜ 1000 ìº”ë“¤")
    print(f"   âš ï¸  Using MAINNET API (production was on mainnet)")

    client = BingXClient(
        api_key=api_config['bingx']['mainnet']['api_key'],
        secret_key=api_config['bingx']['mainnet']['secret_key'],
        testnet=False  # Use mainnet to match production environment
    )

    # Calculate the timestamp for "since" parameter
    # We want 1000 candles ending at target_time_utc
    # The last candle timestamp is 5 minutes before target (candle that completes at target)
    # For 1000 candles: since = target - 5 min - (999 Ã— 5 min) = target - 5000 min
    # But we fetch 1440 to be safe, then filter to last 1000
    # 1440 candles Ã— 5 min = 7200 minutes

    # Calculate since time: we want candles ending at target, so:
    # Last candle at (target - 5min), first candle 999 candles before that
    last_candle_time = target_time_utc - timedelta(minutes=5)
    since_time = last_candle_time - timedelta(minutes=999 * 5)  # 4995 minutes
    since_ms = int(since_time.timestamp() * 1000)

    # Fetch OHLCV data (request max 1440 allowed by BingX API)
    ohlcv = client.exchange.fetch_ohlcv(
        symbol='BTC/USDT:USDT',
        timeframe='5m',
        since=since_ms,
        limit=1440
    )

    # Convert to DataFrame
    df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')

    # Filter to get data up to target time
    df = df[df['timestamp'] <= target_time_utc].copy()

    # Keep only the last 1000 candles (to match production's limit=1000)
    if len(df) > 1000:
        df = df.iloc[-1000:].copy()

    print(f"   âœ… ë°ì´í„° ìˆ˜ì§‘: {len(df)} candles")
    print(f"   ì²« ìº”ë“¤: {df['timestamp'].iloc[0].strftime('%Y-%m-%d %H:%M')} UTC")
    print(f"   ë§ˆì§€ë§‰ ìº”ë“¤: {df['timestamp'].iloc[-1].strftime('%Y-%m-%d %H:%M')} UTC")

    # Verify we got the right ending time
    expected_end = target_time_utc - timedelta(minutes=5)  # Completed candle is 5 min before
    actual_end = df['timestamp'].iloc[-1]

    if actual_end != expected_end:
        print(f"   âš ï¸  Warning: Expected end {expected_end}, got {actual_end}")

    # Calculate backtest signals
    backtest_result = get_backtest_signals(df, models)

    print(f"\nğŸ“Š ë°±í…ŒìŠ¤íŠ¸ ì‹ í˜¸ (Historical data {target_time_kst.strftime('%Y-%m-%d %H:%M KST')}):")
    print(f"   LONG: {backtest_result['long_prob']:.4f} ({backtest_result['long_prob']*100:.2f}%)")
    print(f"   SHORT: {backtest_result['short_prob']:.4f} ({backtest_result['short_prob']*100:.2f}%)")

    # Compare signals
    long_diff = production_signal['long_prob'] - backtest_result['long_prob']
    short_diff = production_signal['short_prob'] - backtest_result['short_prob']

    long_diff_pct = (abs(long_diff) / production_signal['long_prob']) * 100 if production_signal['long_prob'] > 0 else 0
    short_diff_pct = (abs(short_diff) / production_signal['short_prob']) * 100 if production_signal['short_prob'] > 0 else 0

    print("\n" + "=" * 80)
    print("ğŸ“Š ì‹ í˜¸ ì°¨ì´ ë¶„ì„")
    print("=" * 80)

    print(f"\nLONG ì‹ í˜¸ ì°¨ì´:")
    print(f"   í”„ë¡œë•ì…˜: {production_signal['long_prob']:.4f} ({production_signal['long_prob']*100:.2f}%)")
    print(f"   ë°±í…ŒìŠ¤íŠ¸:  {backtest_result['long_prob']:.4f} ({backtest_result['long_prob']*100:.2f}%)")
    print(f"   ì°¨ì´:      {long_diff:+.4f} ({long_diff_pct:+.2f}%)")

    print(f"\nSHORT ì‹ í˜¸ ì°¨ì´:")
    print(f"   í”„ë¡œë•ì…˜: {production_signal['short_prob']:.4f} ({production_signal['short_prob']*100:.2f}%)")
    print(f"   ë°±í…ŒìŠ¤íŠ¸:  {backtest_result['short_prob']:.4f} ({backtest_result['short_prob']*100:.2f}%)")
    print(f"   ì°¨ì´:      {short_diff:+.4f} ({short_diff_pct:+.2f}%)")

    # Severity assessment
    print("\n" + "=" * 80)
    print("âš ï¸  ì‹¬ê°ë„ í‰ê°€")
    print("=" * 80)

    long_abs_diff = abs(long_diff)
    short_abs_diff = abs(short_diff)

    if long_abs_diff > 0.1:
        print(f"\nğŸ”´ LONG ì‹ í˜¸ ì°¨ì´ CRITICAL: {long_abs_diff:.4f} (>0.1 ì„ê³„ê°’)")
    elif long_abs_diff > 0.05:
        print(f"\nğŸŸ¡ LONG ì‹ í˜¸ ì°¨ì´ WARNING: {long_abs_diff:.4f} (>0.05)")
    else:
        print(f"\nğŸŸ¢ LONG ì‹ í˜¸ ì°¨ì´ OK: {long_abs_diff:.4f} (<0.05)")

    if short_abs_diff > 0.1:
        print(f"ğŸ”´ SHORT ì‹ í˜¸ ì°¨ì´ CRITICAL: {short_abs_diff:.4f} (>0.1 ì„ê³„ê°’)")
    elif short_abs_diff > 0.05:
        print(f"ğŸŸ¡ SHORT ì‹ í˜¸ ì°¨ì´ WARNING: {short_abs_diff:.4f} (>0.05)")
    else:
        print(f"ğŸŸ¢ SHORT ì‹ í˜¸ ì°¨ì´ OK: {short_abs_diff:.4f} (<0.05)")

    # Conclusion
    print("\n" + "=" * 80)
    print("âœ… ê²°ë¡ ")
    print("=" * 80)

    print(f"\nì¼ì£¼ì¼ ì „ (10ì›” 28ì¼) ë°±í…ŒìŠ¤íŠ¸ vs í”„ë¡œë•ì…˜ ì‹ í˜¸ ì°¨ì´:")
    print(f"   LONG: {long_diff:+.4f} ({long_diff_pct:+.2f}%)")
    print(f"   SHORT: {short_diff:+.4f} ({short_diff_pct:+.2f}%)")

    if long_abs_diff < 0.05 and short_abs_diff < 0.05:
        print(f"\nâœ… ì‹ í˜¸ ì°¨ì´ê°€ ë§¤ìš° ì‘ìŒ (<5%)")
        print(f"   - ì¼ì£¼ì¼ ì „ì—ë„ ë°±í…ŒìŠ¤íŠ¸ì™€ í”„ë¡œë•ì…˜ì´ ê±°ì˜ ë™ì¼í•œ ì‹ í˜¸ ìƒì„±")
        print(f"   - ë°ì´í„° ë£©ë°± ìœˆë„ìš° ë¶ˆì¼ì¹˜ ê°€ì„¤ì€ í‹€ë ¸ìŒ! (historical ë°ì´í„°ì—ì„œë„ ë™ì¼)")
        print(f"   - ë°±í…ŒìŠ¤íŠ¸ ìˆ˜ìµê³¼ í”„ë¡œë•ì…˜ ì†ì‹¤ì˜ ì°¨ì´ëŠ” ì‹œì¥ regime ë³€í™” ë•Œë¬¸")
    else:
        print(f"\nâš ï¸  ì‹ í˜¸ ì°¨ì´ê°€ ì¡´ì¬í•¨ (>5%)")
        print(f"   - Historical ë°ì´í„°ì—ì„œë„ ë°±í…ŒìŠ¤íŠ¸ â‰  í”„ë¡œë•ì…˜")
        print(f"   - Feature ê³„ì‚°ì´ë‚˜ ëª¨ë¸ ë¡œë”©ì— ì°¨ì´ ìˆì„ ìˆ˜ ìˆìŒ")
        print(f"   - ì¶”ê°€ ë¶„ì„ í•„ìš”: Feature ê°’ ì§ì ‘ ë¹„êµ")

    print("\n" + "=" * 80)

if __name__ == "__main__":
    main()
