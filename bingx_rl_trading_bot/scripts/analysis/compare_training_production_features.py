"""
Compare Training vs Production Feature Distributions
====================================================

Analyzes feature distributions between:
1. Training data (used for Exit model training)
2. Production data (used in backtest)

Purpose: Identify feature mismatch causing poor ML Exit performance

Created: 2025-10-30
"""

import sys
from pathlib import Path
PROJECT_ROOT = Path(__file__).parent.parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

import pandas as pd
import numpy as np
from datetime import datetime

# Import feature calculation functions
from scripts.experiments.calculate_all_features_enhanced_v2 import calculate_all_features_enhanced_v2
from scripts.experiments.retrain_exit_models_opportunity_gating import prepare_exit_features

# Configuration
FEATURES_DIR = PROJECT_ROOT / "data" / "features"
HISTORICAL_DIR = PROJECT_ROOT / "data" / "historical"
LABELS_DIR = PROJECT_ROOT / "data" / "labels"
RESULTS_DIR = PROJECT_ROOT / "results"

# Exit feature columns (21 features)
EXIT_FEATURE_COLUMNS = [
    'rsi_14', 'rsi_9', 'rsi_25',
    'macd', 'macd_signal', 'macd_histogram',
    'bb_upper', 'bb_middle', 'bb_lower', 'bb_width',
    'ema_9', 'ema_21', 'ema_50',
    'volume_sma_20',
    'atr_14',
    'volume_surge', 'price_acceleration',
    'price_vs_ma20', 'price_vs_ma50',
    'volatility_20',
    'rsi_slope', 'rsi_overbought', 'rsi_oversold', 'rsi_divergence',
    'macd_histogram_slope', 'macd_crossover', 'macd_crossunder',
    'bb_position', 'higher_high', 'near_support'
]

print("=" * 80)
print("TRAINING vs PRODUCTION FEATURE DISTRIBUTION COMPARISON")
print("=" * 80)
print()

# ============================================================================
# STEP 1: Load Training Data
# ============================================================================
print("-" * 80)
print("STEP 1: Loading Training Data")
print("-" * 80)

# Load base features (ALREADY ENHANCED - DO NOT CALL prepare_exit_features again!)
df_train = pd.read_csv(FEATURES_DIR / "BTCUSDT_5m_features_enhanced_exit.csv")
df_train['timestamp'] = pd.to_datetime(df_train['timestamp'])

print(f"âœ… Training features loaded (already enhanced): {len(df_train):,} candles")
print(f"   Date range: {df_train['timestamp'].iloc[0]} to {df_train['timestamp'].iloc[-1]}")

# âš ï¸ DO NOT call prepare_exit_features() - features already calculated!
# Training data was generated by generate_enhanced_exit_features.py
# Calling prepare_exit_features() again would DOUBLE-CALCULATE features!

print(f"âœ… Training features ready (no double calculation)")
print()

# ============================================================================
# STEP 2: Load Production Data (Same as Backtest)
# ============================================================================
print("-" * 80)
print("STEP 2: Loading Production Data (Backtest Pipeline)")
print("-" * 80)

# Load raw OHLCV data (same as backtest)
df_prod = pd.read_csv(HISTORICAL_DIR / "BTCUSDT_5m_max.csv")
df_prod['timestamp'] = pd.to_datetime(df_prod['timestamp'])

print(f"âœ… Production raw data loaded: {len(df_prod):,} candles")

# Calculate all features (same as backtest)
print("  Calculating features...")
df_prod = calculate_all_features_enhanced_v2(df_prod, phase='phase1')  # Match training phase!

# Apply feature rename (same as backtest)
feature_rename_map = {
    'macd_diff': 'macd_histogram',
    'bb_high': 'bb_upper',
    'bb_low': 'bb_lower',
    'bb_mid': 'bb_middle'
}
for old_name, new_name in feature_rename_map.items():
    if old_name in df_prod.columns and new_name not in df_prod.columns:
        df_prod[new_name] = df_prod[old_name]
        print(f"  ðŸ“ Renamed: {old_name} â†’ {new_name}")

# Prepare exit features
df_prod = prepare_exit_features(df_prod)

print(f"âœ… Production features prepared")
print()

# ============================================================================
# STEP 3: Align Date Ranges
# ============================================================================
print("-" * 80)
print("STEP 3: Aligning Date Ranges")
print("-" * 80)

# Find overlapping date range
start_date = max(df_train['timestamp'].min(), df_prod['timestamp'].min())
end_date = min(df_train['timestamp'].max(), df_prod['timestamp'].max())

df_train_aligned = df_train[(df_train['timestamp'] >= start_date) &
                             (df_train['timestamp'] <= end_date)].copy()
df_prod_aligned = df_prod[(df_prod['timestamp'] >= start_date) &
                           (df_prod['timestamp'] <= end_date)].copy()

print(f"  Overlapping period: {start_date} to {end_date}")
print(f"  Training data: {len(df_train_aligned):,} candles")
print(f"  Production data: {len(df_prod_aligned):,} candles")
print()

# ============================================================================
# STEP 4: Compare Feature Distributions
# ============================================================================
print("-" * 80)
print("STEP 4: Comparing Feature Distributions")
print("-" * 80)
print()

comparison_results = []

for feature in EXIT_FEATURE_COLUMNS:
    # Skip if feature doesn't exist
    if feature not in df_train_aligned.columns or feature not in df_prod_aligned.columns:
        print(f"âš ï¸ {feature}: Missing in one dataset, skipping")
        continue

    # Get feature values (drop NaN)
    train_vals = df_train_aligned[feature].dropna()
    prod_vals = df_prod_aligned[feature].dropna()

    if len(train_vals) == 0 or len(prod_vals) == 0:
        print(f"âš ï¸ {feature}: Empty data, skipping")
        continue

    # Calculate statistics
    train_stats = {
        'mean': train_vals.mean(),
        'std': train_vals.std(),
        'min': train_vals.min(),
        'q25': train_vals.quantile(0.25),
        'median': train_vals.median(),
        'q75': train_vals.quantile(0.75),
        'max': train_vals.max()
    }

    prod_stats = {
        'mean': prod_vals.mean(),
        'std': prod_vals.std(),
        'min': prod_vals.min(),
        'q25': prod_vals.quantile(0.25),
        'median': prod_vals.median(),
        'q75': prod_vals.quantile(0.75),
        'max': prod_vals.max()
    }

    # Calculate differences
    mean_diff_pct = abs(train_stats['mean'] - prod_stats['mean']) / (abs(train_stats['mean']) + 1e-10) * 100
    std_diff_pct = abs(train_stats['std'] - prod_stats['std']) / (abs(train_stats['std']) + 1e-10) * 100

    # Detect significant mismatch (>10% difference in mean or std)
    is_mismatch = mean_diff_pct > 10 or std_diff_pct > 10

    comparison_results.append({
        'feature': feature,
        'train_mean': train_stats['mean'],
        'prod_mean': prod_stats['mean'],
        'mean_diff_pct': mean_diff_pct,
        'train_std': train_stats['std'],
        'prod_std': prod_stats['std'],
        'std_diff_pct': std_diff_pct,
        'train_min': train_stats['min'],
        'prod_min': prod_stats['min'],
        'train_max': train_stats['max'],
        'prod_max': prod_stats['max'],
        'is_mismatch': is_mismatch
    })

    # Print summary
    status = "ðŸš¨ MISMATCH" if is_mismatch else "âœ… OK"
    print(f"{status} {feature}")
    print(f"     Mean: Train={train_stats['mean']:.4f}, Prod={prod_stats['mean']:.4f} (Î”{mean_diff_pct:.1f}%)")
    print(f"     Std:  Train={train_stats['std']:.4f}, Prod={prod_stats['std']:.4f} (Î”{std_diff_pct:.1f}%)")
    if is_mismatch:
        print(f"     âš ï¸ Significant difference detected!")
    print()

# ============================================================================
# STEP 5: Summary Report
# ============================================================================
print("=" * 80)
print("SUMMARY REPORT")
print("=" * 80)
print()

df_comparison = pd.DataFrame(comparison_results)

# Count mismatches
num_mismatches = df_comparison['is_mismatch'].sum()
num_total = len(df_comparison)
mismatch_rate = num_mismatches / num_total * 100 if num_total > 0 else 0

print(f"Feature Comparison:")
print(f"  Total Features: {num_total}")
print(f"  Mismatched Features: {num_mismatches} ({mismatch_rate:.1f}%)")
print(f"  Matched Features: {num_total - num_mismatches} ({100-mismatch_rate:.1f}%)")
print()

if num_mismatches > 0:
    print("ðŸš¨ MISMATCHED FEATURES (>10% difference):")
    mismatched = df_comparison[df_comparison['is_mismatch']].sort_values('mean_diff_pct', ascending=False)
    for idx, row in mismatched.iterrows():
        print(f"  {row['feature']}:")
        print(f"    Mean: Î”{row['mean_diff_pct']:.1f}% (Train={row['train_mean']:.4f}, Prod={row['prod_mean']:.4f})")
        print(f"    Std:  Î”{row['std_diff_pct']:.1f}% (Train={row['train_std']:.4f}, Prod={row['prod_std']:.4f})")
    print()

# Save results
timestamp_str = datetime.now().strftime("%Y%m%d_%H%M%S")
output_file = RESULTS_DIR / f"feature_comparison_training_prod_{timestamp_str}.csv"
df_comparison.to_csv(output_file, index=False)
print(f"âœ… Results saved: {output_file.name}")
print()

# ============================================================================
# STEP 6: Check Feature Existence
# ============================================================================
print("-" * 80)
print("STEP 6: Feature Existence Check")
print("-" * 80)
print()

print("Training Data Features:")
train_has = [f for f in EXIT_FEATURE_COLUMNS if f in df_train_aligned.columns]
train_missing = [f for f in EXIT_FEATURE_COLUMNS if f not in df_train_aligned.columns]
print(f"  Present: {len(train_has)}/{len(EXIT_FEATURE_COLUMNS)}")
if train_missing:
    print(f"  Missing: {train_missing}")
print()

print("Production Data Features:")
prod_has = [f for f in EXIT_FEATURE_COLUMNS if f in df_prod_aligned.columns]
prod_missing = [f for f in EXIT_FEATURE_COLUMNS if f not in df_prod_aligned.columns]
print(f"  Present: {len(prod_has)}/{len(EXIT_FEATURE_COLUMNS)}")
if prod_missing:
    print(f"  Missing: {prod_missing}")
print()

# ============================================================================
# CONCLUSION
# ============================================================================
print("=" * 80)
print("CONCLUSION")
print("=" * 80)
print()

if num_mismatches > 0:
    print("ðŸš¨ FEATURE MISMATCH DETECTED!")
    print(f"   {num_mismatches} features have significant distribution differences (>10%)")
    print(f"   This likely explains the poor ML Exit performance (1.6% usage)")
    print()
    print("Recommended Actions:")
    print("  1. Review feature calculation in calculate_all_features_enhanced_v2()")
    print("  2. Review feature preparation in prepare_exit_features()")
    print("  3. Ensure Training and Production use identical feature calculation")
    print("  4. Consider retraining Exit models with Production feature pipeline")
else:
    print("âœ… NO SIGNIFICANT FEATURE MISMATCH")
    print("   Features distributions match between Training and Production")
    print()
    print("Possible other causes for poor ML Exit performance:")
    print("  1. Threshold too high (0.75) - consider lowering to 0.50-0.60")
    print("  2. Peak/Trough labeling doesn't match production conditions")
    print("  3. Model overfitting to training data")
print()

print("âœ… Feature comparison complete!")
print()
