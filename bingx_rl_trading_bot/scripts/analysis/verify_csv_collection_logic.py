#!/usr/bin/env python3
"""
CSV Collection Logic Verification
collect_max_data.pyì˜ ë°ì´í„° ìˆ˜ì§‘ ë¡œì§ ê²€ì¦
"""

import pandas as pd
import ccxt
from datetime import datetime
import pytz
from pathlib import Path

PROJECT_ROOT = Path(__file__).parent.parent.parent

print("=" * 80)
print("CSV COLLECTION LOGIC VERIFICATION")
print("collect_max_data.py ë¡œì§ ì •ë°€ ê²€ì¦")
print("=" * 80)

# Initialize exchange (same as collect_max_data.py)
exchange = ccxt.bingx({
    'enableRateLimit': True,
    'options': {'defaultType': 'swap'},
})

symbol = 'BTC/USDT:USDT'
timeframe = '5m'

# Target timestamp
target_timestamp_ms = int(datetime(2025, 10, 26, 15, 25, 0, tzinfo=pytz.UTC).timestamp() * 1000)

print(f"\nğŸ¯ Target: 2025-10-26 15:25:00 UTC (Timestamp: {target_timestamp_ms})")

# 1. Fetch with 'since' parameter (like collect_max_data.py backward collection)
print(f"\n1ï¸âƒ£ Fetch with 'since' (ë°±ì›Œë“œ ìˆ˜ì§‘ ë°©ì‹ ì‹œë®¬ë ˆì´ì…˜)")
print("-" * 80)

# Fetch data starting from target timestamp
ohlcv = exchange.fetch_ohlcv(symbol, timeframe, since=target_timestamp_ms, limit=10)

print(f"\nFetch ê²°ê³¼: {len(ohlcv)} ìº”ë“¤")
print(f"\nì²« 3ê°œ ìº”ë“¤:")
for i, candle in enumerate(ohlcv[:3]):
    ts_ms = candle[0]
    dt_utc = datetime.fromtimestamp(ts_ms/1000, pytz.UTC)
    print(f"  {i}: {dt_utc.strftime('%Y-%m-%d %H:%M:%S')} | Close: ${candle[4]:.1f} | Vol: {candle[5]:.4f}")

# Find target candle
target_candle = None
for candle in ohlcv:
    if candle[0] == target_timestamp_ms:
        target_candle = candle
        break

if target_candle:
    print(f"\nâœ… Target ìº”ë“¤ ë°œê²¬:")
    print(f"   Timestamp: {target_timestamp_ms}")
    print(f"   Close: ${target_candle[4]:.1f}")
    print(f"   Volume: {target_candle[5]:.4f}")
else:
    print(f"\nâŒ Target ìº”ë“¤ ì—†ìŒ")

# 2. DataFrame conversion test (exactly as collect_max_data.py does)
print(f"\n2ï¸âƒ£ DataFrame ë³€í™˜ í…ŒìŠ¤íŠ¸ (collect_max_data.py Line 110-113)")
print("-" * 80)

df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])

print(f"\nBefore pd.to_datetime(unit='ms'):")
print(f"  Dtype: {df['timestamp'].dtype}")
print(f"  First value (raw): {df.iloc[0]['timestamp']}")

# This is the EXACT line from collect_max_data.py Line 111
df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')

print(f"\nAfter pd.to_datetime(unit='ms'):")
print(f"  Dtype: {df['timestamp'].dtype}")
print(f"  Timezone aware? {df['timestamp'].dt.tz is not None}")
print(f"  First value: {df.iloc[0]['timestamp']}")

# What string would be saved to CSV?
csv_timestamp_str = df.iloc[0]['timestamp'].strftime('%Y-%m-%d %H:%M:%S')
print(f"\nCSVì— ì €ì¥ë  ë¬¸ìì—´: '{csv_timestamp_str}'")

# 3. Check if timestamp matches target
print(f"\n3ï¸âƒ£ Timestamp ë§¤ì¹­ í™•ì¸")
print("-" * 80)

target_str = '2025-10-26 15:25:00'
target_dt = pd.to_datetime(target_str)

print(f"\nTarget string: '{target_str}'")
print(f"Target datetime: {target_dt}")

# Search in DataFrame
df_match = df[df['timestamp'] == target_dt]

if len(df_match) > 0:
    print(f"\nâœ… DataFrameì—ì„œ ë°œê²¬:")
    print(f"   Close: ${df_match.iloc[0]['close']:.1f}")
    print(f"   Volume: {df_match.iloc[0]['volume']:.4f}")
else:
    print(f"\nâŒ DataFrameì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŒ")

# 4. Check actual CSV file
print(f"\n4ï¸âƒ£ ì‹¤ì œ CSV íŒŒì¼ í™•ì¸")
print("-" * 80)

CSV_FILE = PROJECT_ROOT / "data" / "historical" / "BTCUSDT_5m_max.csv"
df_csv = pd.read_csv(CSV_FILE)
df_csv['timestamp'] = pd.to_datetime(df_csv['timestamp'])

csv_match = df_csv[df_csv['timestamp'] == target_dt]

if len(csv_match) > 0:
    csv_close = csv_match.iloc[0]['close']
    csv_volume = csv_match.iloc[0]['volume']
    print(f"\nâœ… CSVì—ì„œ ë°œê²¬:")
    print(f"   Close: ${csv_close:.1f}")
    print(f"   Volume: {csv_volume:.4f}")

    # Compare with current API
    if target_candle:
        close_diff = abs(csv_close - target_candle[4])
        vol_diff = abs(csv_volume - target_candle[5])
        print(f"\n   í˜„ì¬ APIì™€ ë¹„êµ:")
        print(f"      Close ì°¨ì´: ${close_diff:.2f}")
        print(f"      Volume ì°¨ì´: {vol_diff:.4f}")
else:
    print(f"\nâŒ CSVì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŒ")

# 5. Test incomplete candle filtering (collect_max_data.py logic)
print(f"\n5ï¸âƒ£ ë¯¸ì™„ì„± ìº”ë“¤ í•„í„°ë§ ë¡œì§ ê²€ì¦")
print("-" * 80)

# Get current time
current_time = datetime.now(pytz.UTC)
print(f"\nCurrent time (UTC): {current_time.strftime('%Y-%m-%d %H:%M:%S')}")

# Calculate current candle start (5m intervals)
current_candle_start = current_time.replace(second=0, microsecond=0)
minutes_to_subtract = current_candle_start.minute % 5
if minutes_to_subtract > 0:
    from datetime import timedelta
    current_candle_start = current_candle_start - timedelta(minutes=minutes_to_subtract)

print(f"Current candle start: {current_candle_start.strftime('%Y-%m-%d %H:%M:%S')}")

# Filter completed candles
df_filtered = df[df['timestamp'] < current_candle_start].copy()

print(f"\ní•„í„°ë§ ì „: {len(df)} ìº”ë“¤")
print(f"í•„í„°ë§ í›„: {len(df_filtered)} ìº”ë“¤ (ì™„ì„±ëœ ìº”ë“¤ë§Œ)")

# 6. Check CSV update timestamp vs target candle
print(f"\n6ï¸âƒ£ CSV ì—…ë°ì´íŠ¸ ì‹œê°„ vs Target ìº”ë“¤ ì‹œê°„")
print("-" * 80)

import os
csv_mtime = os.path.getmtime(CSV_FILE)
csv_update_time = datetime.fromtimestamp(csv_mtime, pytz.UTC)

print(f"\nCSV íŒŒì¼ ì—…ë°ì´íŠ¸ ì‹œê°„: {csv_update_time.strftime('%Y-%m-%d %H:%M:%S %Z')}")

target_candle_end = datetime(2025, 10, 26, 15, 30, 0, tzinfo=pytz.UTC)
time_diff_minutes = (csv_update_time - target_candle_end).total_seconds() / 60

print(f"Target ìº”ë“¤ ì¢…ë£Œ ì‹œê°„: {target_candle_end.strftime('%Y-%m-%d %H:%M:%S %Z')}")
print(f"ì‹œê°„ ì°¨ì´: {time_diff_minutes:.1f} ë¶„")

if time_diff_minutes > 0:
    print(f"âœ… CSV ì—…ë°ì´íŠ¸ê°€ ìº”ë“¤ ì¢…ë£Œ í›„ {time_diff_minutes:.1f}ë¶„ ë’¤ â†’ ìº”ë“¤ ì™„ì„±ë¨")
else:
    print(f"âš ï¸ CSV ì—…ë°ì´íŠ¸ê°€ ìº”ë“¤ ì¢…ë£Œ ì „ â†’ ë¯¸ì™„ì„± ìº”ë“¤ í¬í•¨ ê°€ëŠ¥")

# 7. Test duplicate handling
print(f"\n7ï¸âƒ£ ì¤‘ë³µ ì²˜ë¦¬ ë¡œì§ ê²€ì¦ (drop_duplicates)")
print("-" * 80)

# Create test data with duplicates
test_data = [
    [target_timestamp_ms, 100.0, 101.0, 99.0, 100.5, 10.0],
    [target_timestamp_ms, 100.0, 101.0, 99.0, 200.5, 20.0],  # Duplicate with different data
]

df_dup = pd.DataFrame(test_data, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
df_dup['timestamp'] = pd.to_datetime(df_dup['timestamp'], unit='ms')

print(f"\nì¤‘ë³µ ì „:")
print(df_dup[['timestamp', 'close', 'volume']])

# Apply drop_duplicates with keep='last' (Line 112 in collect_max_data.py)
df_dup = df_dup.drop_duplicates(subset=['timestamp'], keep='last')

print(f"\nì¤‘ë³µ ì œê±° í›„ (keep='last'):")
print(df_dup[['timestamp', 'close', 'volume']])
print(f"\nKeep='last' â†’ ë§ˆì§€ë§‰ ë°ì´í„° ìœ ì§€ (Close: 200.5, Volume: 20.0)")

print("\n" + "=" * 80)
print("ğŸ¯ ë¶„ì„ ê²°ê³¼")
print("=" * 80)

print("""
ê²€ì¦ ê²°ê³¼:

1. DataFrame ë³€í™˜ ë¡œì§:
   - pd.to_datetime(timestamp, unit='ms')ëŠ” timezone-naive datetime ìƒì„±
   - CSV ì €ì¥ ì‹œ 'YYYY-MM-DD HH:MM:SS' í˜•ì‹ìœ¼ë¡œ ì €ì¥ë¨
   - ì½ì„ ë•Œ pd.read_csv() + pd.to_datetime()ì€ ë™ì¼í•œ datetime ìƒì„±
   - âœ… ë³€í™˜ ë¡œì§ì€ ì •ìƒ

2. ë¯¸ì™„ì„± ìº”ë“¤ í•„í„°ë§:
   - í˜„ì¬ ìº”ë“¤ ì‹œì‘ ì‹œê°„ ì´ì „ë§Œ ì €ì¥
   - âœ… í•„í„°ë§ ë¡œì§ ì •ìƒ

3. ì¤‘ë³µ ì²˜ë¦¬:
   - drop_duplicates(keep='last')ëŠ” ë§ˆì§€ë§‰ ë°ì´í„° ìœ ì§€
   - ë°°ì¹˜ ìˆ˜ì§‘ ì‹œ ë‚˜ì¤‘ ë°°ì¹˜ ë°ì´í„°ë¡œ ë®ì–´ì”€
   - âš ï¸ ë§Œì•½ ë°°ì¹˜ê°€ ë‹¤ë¥¸ ë°ì´í„° ë°˜í™˜í•˜ë©´ ë¬¸ì œ ë°œìƒ ê°€ëŠ¥

4. CSV ì—…ë°ì´íŠ¸ ì‹œê°„:
   - Target ìº”ë“¤ ì¢…ë£Œ í›„ 66ë¶„ ë’¤ ì—…ë°ì´íŠ¸
   - âœ… ìº”ë“¤ì€ ì™„ì„±ë˜ì—ˆì–´ì•¼ í•¨

ê²°ë¡ :
- collect_max_data.py ë¡œì§ ìì²´ëŠ” ë¬¸ì œ ì—†ìŒ
- í•˜ì§€ë§Œ CSV ë°ì´í„°ì™€ í˜„ì¬ API ë°ì´í„°ê°€ ë‹¤ë¦„
- ê°€ëŠ¥ì„±: ë°°ì¹˜ ìˆ˜ì§‘ ì‹œ APIê°€ ë‹¤ë¥¸ ë°ì´í„° ë°˜í™˜?
""")

print("=" * 80)
