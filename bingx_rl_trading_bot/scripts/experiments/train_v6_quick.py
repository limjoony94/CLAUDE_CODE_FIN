"""V6 ë¹ ë¥¸ ê²€ì¦ í›ˆë ¨ - 15ë¶„ë´‰ + ì ì‘í˜• ë³´ìƒ"""

import sys
from pathlib import Path
import pandas as pd

project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.environment.trading_env_v6 import TradingEnvironmentV6
from src.agent.rl_agent import RLAgent
from src.indicators.technical_indicators import TechnicalIndicators
from src.data.data_processor import DataProcessor
from src.utils.config_loader import ConfigLoader
from loguru import logger


def main():
    logger.info("="*70)
    logger.info("V6 QUICK TEST - Adaptive Reward Scale + 15min")
    logger.info("="*70)
    logger.info("")
    logger.info("ğŸ”‘ í•µì‹¬ ê°œì„ ì‚¬í•­:")
    logger.info("  1. ì ì‘í˜• ë³´ìƒ ìŠ¤ì¼€ì¼ (volatility ê¸°ë°˜)")
    logger.info("  2. í–‰ë™ ê³µê°„ ê±°ë˜ ì œì•½ (í˜ë„í‹° ì œê±°)")
    logger.info("  3. 15ë¶„ë´‰ (ë…¸ì´ì¦ˆ ê°ì†Œ, ìˆ˜ìˆ˜ë£Œ 1/3)")
    logger.info("  4. ì†ì ˆ/ìµì ˆ ì™„í™” (3%/5%)")
    logger.info("="*70)

    # 15ë¶„ë´‰ ë°ì´í„° ë¡œë“œ
    df = pd.read_csv('data/historical/BTCUSDT_15m.csv', parse_dates=['timestamp'])
    logger.info(f"\nâœ“ Loaded 15-minute data: {len(df):,} candles")

    # ì§€í‘œ ê³„ì‚°
    indicator_calc = TechnicalIndicators()
    df = indicator_calc.calculate_all_indicators(df)
    logger.info(f"âœ“ Calculated indicators: {len(df):,} rows")

    # ì „ì²˜ë¦¬
    processor = DataProcessor()
    df = processor.prepare_data(df, fit=True)
    logger.info(f"âœ“ Preprocessed: {len(df):,} rows")

    # ë°ì´í„° ë¶„í• 
    train_size = int(len(df) * 0.7)
    val_size = int(len(df) * 0.15)

    train_df = df.iloc[:train_size]
    val_df = df.iloc[train_size:train_size+val_size]
    test_df = df.iloc[train_size+val_size:]

    logger.info(f"âœ“ Split - Train: {len(train_df):,}, Val: {len(val_df):,}, Test: {len(test_df):,}")

    # V6 í™˜ê²½ ìƒì„±
    logger.info(f"\n{'='*70}")
    logger.info("Creating V6 environments...")
    logger.info(f"{'='*70}")

    train_env = TradingEnvironmentV6(
        df=train_df,
        initial_balance=10000.0,
        leverage=3,
        transaction_fee=0.0004,
        slippage=0.0001,
        max_position_size=0.03,
        stop_loss_pct=0.03,  # 3%
        take_profit_pct=0.05,  # 5%
        min_hold_steps=10,
        volatility_window=50
    )

    val_env = TradingEnvironmentV6(
        df=val_df,
        initial_balance=10000.0,
        leverage=3,
        transaction_fee=0.0004,
        slippage=0.0001,
        max_position_size=0.03,
        stop_loss_pct=0.03,
        take_profit_pct=0.05,
        min_hold_steps=10,
        volatility_window=50
    )

    # ì—ì´ì „íŠ¸ ìƒì„±
    config_loader = ConfigLoader()
    config = config_loader.load_config()

    agent = RLAgent(env=train_env, config=config['rl'])
    agent.create_model()

    # í›ˆë ¨
    logger.info(f"\n{'='*70}")
    logger.info("TRAINING (500K timesteps for quick validation)")
    logger.info(f"{'='*70}")
    logger.info("Expected outcomes:")
    logger.info("  âœ“ Action diversity (std > 0.1)")
    logger.info("  âœ“ Trade frequency 5~15%")
    logger.info("  âœ“ NO Mode Collapse")
    logger.info("  âœ“ Test return > 0%")
    logger.info(f"{'='*70}\n")

    agent.train(
        total_timesteps=500000,
        eval_env=val_env,
        eval_freq=50000,
        save_freq=100000
    )

    logger.info("\nâœ“ Training complete!")
    agent.save_model('v6_quick_test')

    # í…ŒìŠ¤íŠ¸
    logger.info(f"\n{'='*70}")
    logger.info("TESTING on test set...")
    logger.info(f"{'='*70}")

    test_env = TradingEnvironmentV6(
        df=test_df,
        initial_balance=10000.0,
        leverage=3,
        transaction_fee=0.0004,
        slippage=0.0001,
        max_position_size=0.03,
        stop_loss_pct=0.03,
        take_profit_pct=0.05,
        min_hold_steps=10,
        volatility_window=50
    )

    agent.env = test_env
    stats = agent.evaluate(n_episodes=10, deterministic=True)

    logger.info(f"\n{'='*70}")
    logger.info("QUICK TEST RESULTS")
    logger.info(f"{'='*70}")
    logger.info(f"Mean Reward: {stats['mean_reward']:.2f}")
    logger.info(f"Est. Return: {stats['mean_reward']/10000*100:.4f}% (rough estimate)")
    logger.info(f"{'='*70}")

    # ì‹¤ì œ ë°±í…ŒìŠ¤íŒ…
    logger.info("\nRunning actual backtest...")
    obs, info = test_env.reset()
    done = False

    initial_value = info['portfolio_value']

    # í–‰ë™ ë¶„ì„ìš©
    actions = []
    rewards_list = []

    while not done:
        action, _ = agent.predict(obs, deterministic=True)
        actions.append(action[0])

        obs, reward, terminated, truncated, info = test_env.step(action)
        rewards_list.append(reward)

        done = terminated or truncated

    final_value = info['portfolio_value']
    actual_return = (final_value - initial_value) / initial_value * 100

    # í–‰ë™ ë¶„ì„
    actions = pd.Series(actions)

    logger.info(f"\n{'='*70}")
    logger.info("DETAILED RESULTS")
    logger.info(f"{'='*70}")
    logger.info(f"Portfolio:")
    logger.info(f"  Initial: ${initial_value:,.2f}")
    logger.info(f"  Final: ${final_value:,.2f}")
    logger.info(f"  Return: {actual_return:.2f}%")

    logger.info(f"\nTrading:")
    logger.info(f"  Total Trades: {info['trade_count']}")
    logger.info(f"  Trade Frequency: {info['trade_count']/len(test_df)*100:.2f}%")
    logger.info(f"  Win Rate: {info['win_rate']*100:.2f}%")

    logger.info(f"\nAction Analysis:")
    logger.info(f"  Mean: {actions.mean():.4f}")
    logger.info(f"  Std: {actions.std():.4f}")
    logger.info(f"  Min/Max: {actions.min():.4f} / {actions.max():.4f}")

    logger.info(f"\nReward Analysis:")
    rewards_arr = pd.Series(rewards_list)
    logger.info(f"  Mean: {rewards_arr.mean():.4f}")
    logger.info(f"  Std: {rewards_arr.std():.2f}")
    logger.info(f"  Min/Max: {rewards_arr.min():.2f} / {rewards_arr.max():.2f}")

    # ì„±ê³µ í‰ê°€
    logger.info(f"\n{'='*70}")
    logger.info("SUCCESS CRITERIA EVALUATION")
    logger.info(f"{'='*70}")

    criteria = {
        "Action Diversity (std > 0.1)": actions.std() > 0.1,
        "Trade Frequency 5~15%": 5 < (info['trade_count']/len(test_df)*100) < 15,
        "Test Return > 0%": actual_return > 0,
        "Mode Collapse Avoided": actions.std() > 0.05
    }

    for criterion, passed in criteria.items():
        status = "âœ… PASS" if passed else "âŒ FAIL"
        logger.info(f"  {status} - {criterion}")

    success_rate = sum(criteria.values()) / len(criteria) * 100
    logger.info(f"\nOverall Success: {success_rate:.0f}% ({sum(criteria.values())}/{len(criteria)})")

    if success_rate >= 75:
        logger.info(f"\nğŸ‰ V6 ê²€ì¦ ì„±ê³µ! ì „ì²´ í›ˆë ¨ ì§„í–‰ ê¶Œì¥")
    elif success_rate >= 50:
        logger.info(f"\nâš ï¸  ë¶€ë¶„ ì„±ê³µ. íŒŒë¼ë¯¸í„° ì¡°ì • í›„ ì¬ì‹œë„ ê¶Œì¥")
    else:
        logger.info(f"\nâŒ ê²€ì¦ ì‹¤íŒ¨. ì¶”ê°€ ë¶„ì„ í•„ìš”")

    logger.info(f"\n{'='*70}\n")


if __name__ == "__main__":
    main()
