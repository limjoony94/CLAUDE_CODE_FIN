"""V6: ì ì‘í˜• ë³´ìƒ ìŠ¤ì¼€ì¼ + í–‰ë™ ì œì•½ - ê·¼ë³¸ ì›ì¸ í•´ê²°"""

from typing import Dict, Any, Tuple, Optional
import gymnasium as gym
import numpy as np
import pandas as pd
from gymnasium import spaces
from loguru import logger


class TradingEnvironmentV6(gym.Env):
    """
    V6 í•µì‹¬ ê°œì„ ì‚¬í•­:
    1. ì ì‘í˜• ë³´ìƒ ìŠ¤ì¼€ì¼ (volatility ê¸°ë°˜, Mode Collapse í•´ê²°)
    2. í–‰ë™ ê³µê°„ì—ì„œ ê±°ë˜ ë¹ˆë„ ë¬¼ë¦¬ì  ì œì•½ (í˜ë„í‹° ì•„ë‹˜)
    3. ì†ì ˆ/ìµì ˆ ì™„í™” (3%/5%)
    4. ìˆœìˆ˜ í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥ ë§Œ ë³´ìƒ (í˜ë„í‹° ì™„ì „ ì œê±°)

    ê·¼ë³¸ ì›ì¸ í•´ê²°:
    - ë³´ìƒ ìŠ¤ì¼€ì¼ ë¶ˆê· í˜• â†’ ì ì‘í˜• ìŠ¤ì¼€ì¼ë¡œ í•´ê²°
    - Mode Collapse â†’ ê±°ë˜ ë¬¼ë¦¬ì  ê°•ì œë¡œ ë‹¤ì–‘ì„± í™•ë³´
    - ë³´ìƒ ì™œê³¡ â†’ í˜ë„í‹° ì œê±°, ìˆœìˆ˜ ìˆ˜ìµë¥ ë§Œ
    """

    metadata = {'render_modes': ['human']}

    def __init__(
        self,
        df: pd.DataFrame,
        initial_balance: float = 10000.0,
        leverage: int = 3,
        transaction_fee: float = 0.0004,
        slippage: float = 0.0001,
        max_position_size: float = 0.03,
        stop_loss_pct: float = 0.03,  # 2% â†’ 3%
        take_profit_pct: float = 0.05,  # 3% â†’ 5%
        min_hold_steps: int = 10,
        volatility_window: int = 50  # ì ì‘í˜• ìŠ¤ì¼€ì¼ìš©
    ):
        super().__init__()

        self.df = df.reset_index(drop=True)
        self.initial_balance = initial_balance
        self.leverage = leverage
        self.transaction_fee = transaction_fee
        self.slippage = slippage
        self.max_position_size = max_position_size
        self.stop_loss_pct = stop_loss_pct
        self.take_profit_pct = take_profit_pct
        self.min_hold_steps = min_hold_steps
        self.volatility_window = volatility_window

        # íŠ¹ì„±
        self.feature_columns = self._select_features()
        n_features = len(self.feature_columns) + 5

        self.observation_space = spaces.Box(
            low=-np.inf,
            high=np.inf,
            shape=(n_features,),
            dtype=np.float32
        )

        # í–‰ë™: í¬ì§€ì…˜ë§Œ
        self.action_space = spaces.Box(
            low=np.array([-1.0]),
            high=np.array([1.0]),
            dtype=np.float32
        )

        # ìƒíƒœ
        self.current_step = 0
        self.balance = initial_balance
        self.position = 0.0
        self.entry_price = 0.0
        self.entry_step = 0
        self.last_trade_step = 0  # ë§ˆì§€ë§‰ ê±°ë˜ ì‹œì 
        self.total_pnl = 0.0
        self.trade_count = 0
        self.win_count = 0

        # ì ì‘í˜• ìŠ¤ì¼€ì¼ìš© í†µê³„
        self.recent_returns = []
        self.current_volatility = 0.002  # ì´ˆê¸°ê°’

        logger.info(f"Trading Environment V6 (Adaptive Reward Scale) - {len(self.df)} steps")
        logger.info(f"  - Adaptive reward scaling based on {volatility_window}-step volatility")
        logger.info(f"  - Physical action constraint (min_hold: {min_hold_steps})")
        logger.info(f"  - Pure PnL reward (NO penalties)")
        logger.info(f"  - Stop loss: {stop_loss_pct*100}%, Take profit: {take_profit_pct*100}%")

    def _select_features(self) -> list:
        return [
            'close', 'volume',
            'ema_9', 'ema_21', 'ema_50',
            'rsi',
            'macd', 'macd_signal',
            'bb_upper', 'bb_middle', 'bb_lower',
            'atr'
        ]

    def reset(
        self,
        seed: Optional[int] = None,
        options: Optional[Dict[str, Any]] = None
    ) -> Tuple[np.ndarray, Dict[str, Any]]:
        super().reset(seed=seed)

        self.current_step = 0
        self.balance = self.initial_balance
        self.position = 0.0
        self.entry_price = 0.0
        self.entry_step = 0
        self.last_trade_step = 0
        self.total_pnl = 0.0
        self.trade_count = 0
        self.win_count = 0

        self.recent_returns = []
        self.current_volatility = 0.002

        return self._get_observation(), self._get_info()

    def step(
        self,
        action: np.ndarray
    ) -> Tuple[np.ndarray, float, bool, bool, Dict[str, Any]]:
        current_price = self._get_current_price()
        prev_portfolio = self._calculate_portfolio_value()

        # í¬ì§€ì…˜ ëª©í‘œ
        target_position = np.clip(float(action[0]), -1.0, 1.0)
        target_position_size = target_position * self.max_position_size

        # ğŸ”‘ í•µì‹¬: ìµœì†Œ í™€ë”© ê¸°ê°„ ë¬¼ë¦¬ì  ê°•ì œ
        if self.current_step - self.last_trade_step < self.min_hold_steps:
            # ê±°ë˜ ë¶ˆê°€ â†’ í˜„ì¬ í¬ì§€ì…˜ ìœ ì§€
            target_position_size = self.position

        # ê±°ë˜ ì‹¤í–‰
        position_change = target_position_size - self.position
        trade_pnl = self._execute_trade(position_change, current_price)

        # ê±°ë˜ ë°œìƒ ì‹œ ê¸°ë¡
        if abs(position_change) > 0.001:
            self.last_trade_step = self.current_step

        # ìŠ¤í… ì´ë™
        self.current_step += 1

        # ì†ì ˆ/ìµì ˆ
        if self.current_step < len(self.df):
            next_price = self._get_current_price()
            self._check_stop_conditions(next_price)

        # ğŸ”‘ V6 ë³´ìƒ: ì ì‘í˜• ìŠ¤ì¼€ì¼ + ìˆœìˆ˜ ìˆ˜ìµë¥ 
        new_portfolio = self._calculate_portfolio_value()
        reward = self._calculate_reward_v6(prev_portfolio, new_portfolio)

        # í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥  ê¸°ë¡ (ì ì‘í˜• ìŠ¤ì¼€ì¼ìš©)
        portfolio_return = (new_portfolio - prev_portfolio) / prev_portfolio if prev_portfolio > 0 else 0.0
        self._update_volatility(portfolio_return)

        terminated = self.balance <= 0 or self.current_step >= len(self.df) - 1
        truncated = False

        return self._get_observation(), reward, terminated, truncated, self._get_info()

    def _get_observation(self) -> np.ndarray:
        row = self.df.iloc[self.current_step]

        # ì‹œì¥ íŠ¹ì„±
        market_features = [float(row[col]) for col in self.feature_columns]

        # ì‹œì¥ ì²´ì œ
        market_regime = self._detect_market_regime()

        # ê³„ì •
        position_norm = self.position / self.max_position_size
        balance_ratio = self.balance / self.initial_balance
        pnl_ratio = self.total_pnl / self.initial_balance

        observation = np.array(
            market_features + list(market_regime) + [position_norm, balance_ratio, pnl_ratio],
            dtype=np.float32
        )

        return np.nan_to_num(observation, nan=0.0, posinf=1.0, neginf=-1.0)

    def _detect_market_regime(self) -> Tuple[float, float]:
        """ì‹œì¥ ì²´ì œ ê°ì§€"""
        if self.current_step < 50:
            return (0.0, 0.0)

        start_idx = max(0, self.current_step - 50)
        recent = self.df.iloc[start_idx:self.current_step + 1]

        # ì¶”ì„¸ ê°•ë„
        if recent['close'].iloc[0] > 0:
            price_change = (recent['close'].iloc[-1] - recent['close'].iloc[0]) / recent['close'].iloc[0]
            trend_strength = np.clip(price_change * 20, -1.0, 1.0)
        else:
            trend_strength = 0.0

        # ë³€ë™ì„± ì²´ì œ
        volatility = recent['close'].pct_change().std()
        avg_volatility = 0.002
        volatility_regime = np.clip(volatility / avg_volatility, 0.0, 2.0) - 1.0

        return (trend_strength, volatility_regime)

    def _update_volatility(self, portfolio_return: float) -> None:
        """ì ì‘í˜• ìŠ¤ì¼€ì¼ìš© ë³€ë™ì„± ì—…ë°ì´íŠ¸"""
        self.recent_returns.append(portfolio_return)

        # ìµœê·¼ windowë§Œ ìœ ì§€
        if len(self.recent_returns) > self.volatility_window:
            self.recent_returns.pop(0)

        # ë³€ë™ì„± ê³„ì‚°
        if len(self.recent_returns) >= 10:
            self.current_volatility = max(np.std(self.recent_returns), 0.0001)  # ìµœì†Œê°’ ë°©ì§€
        else:
            self.current_volatility = 0.002  # ì´ˆê¸° ê¸°ë³¸ê°’

    def _get_info(self) -> Dict[str, Any]:
        current_price = self._get_current_price()

        return {
            'step': self.current_step,
            'balance': self.balance,
            'position': self.position,
            'portfolio_value': self._calculate_portfolio_value(),
            'total_pnl': self.total_pnl,
            'trade_count': self.trade_count,
            'win_rate': self.win_count / max(self.trade_count, 1),
            'current_price': current_price,
            'unrealized_pnl': self._calculate_unrealized_pnl(current_price),
            'current_volatility': self.current_volatility,  # ë””ë²„ê¹…ìš©
            'last_trade_step': self.last_trade_step
        }

    def _get_current_price(self) -> float:
        if self.current_step >= len(self.df):
            return self.df.iloc[-1]['close']
        return self.df.iloc[self.current_step]['close']

    def _execute_trade(self, position_change: float, price: float) -> float:
        if abs(position_change) < 0.001:
            return 0.0

        execution_price = price * (1 + self.slippage * np.sign(position_change))
        trade_value = abs(position_change) * execution_price * self.leverage
        fee = trade_value * self.transaction_fee

        realized_pnl = 0.0

        # ê¸°ì¡´ í¬ì§€ì…˜ ì²­ì‚°
        if abs(self.position) > 0.001 and np.sign(position_change) != np.sign(self.position):
            close_size = min(abs(position_change), abs(self.position))
            price_diff = (execution_price - self.entry_price) * np.sign(self.position)
            realized_pnl = close_size * price_diff * self.leverage - fee

            self.balance += realized_pnl
            self.total_pnl += realized_pnl

            self.trade_count += 1
            if realized_pnl > 0:
                self.win_count += 1

        # ìƒˆ í¬ì§€ì…˜ ì§„ì…
        remaining_change = position_change
        if abs(self.position) > 0.001 and np.sign(position_change) != np.sign(self.position):
            remaining_change = position_change + self.position

        if abs(remaining_change) > 0.001:
            required_margin = abs(remaining_change) * execution_price / self.leverage

            if required_margin <= self.balance:
                self.position += remaining_change
                self.entry_price = execution_price
                self.entry_step = self.current_step
                self.balance -= fee

        return realized_pnl

    def _check_stop_conditions(self, current_price: float) -> None:
        if abs(self.position) < 0.001:
            return

        if self.position > 0:
            stop_loss = self.entry_price * (1 - self.stop_loss_pct)
            take_profit = self.entry_price * (1 + self.take_profit_pct)

            if current_price <= stop_loss or current_price >= take_profit:
                self._execute_trade(-self.position, current_price)

        elif self.position < 0:
            stop_loss = self.entry_price * (1 + self.stop_loss_pct)
            take_profit = self.entry_price * (1 - self.take_profit_pct)

            if current_price >= stop_loss or current_price <= take_profit:
                self._execute_trade(-self.position, current_price)

    def _calculate_unrealized_pnl(self, current_price: float) -> float:
        if abs(self.position) < 0.001:
            return 0.0

        price_diff = (current_price - self.entry_price) * np.sign(self.position)
        return abs(self.position) * price_diff * self.leverage

    def _calculate_portfolio_value(self) -> float:
        current_price = self._get_current_price()
        unrealized_pnl = self._calculate_unrealized_pnl(current_price)
        return self.balance + unrealized_pnl

    def _calculate_reward_v6(
        self,
        prev_value: float,
        new_value: float
    ) -> float:
        """
        V6 ë³´ìƒ í•¨ìˆ˜: ì ì‘í˜• ìŠ¤ì¼€ì¼ + ìˆœìˆ˜ ìˆ˜ìµë¥ 

        í•µì‹¬ ê°œì„ :
        1. ì ì‘í˜• ìŠ¤ì¼€ì¼: volatility ê¸°ë°˜ìœ¼ë¡œ ë™ì  ì¡°ì •
        2. í˜ë„í‹° ì™„ì „ ì œê±°: í–‰ë™ ì œì•½ìœ¼ë¡œ ëŒ€ì²´
        3. ìˆœìˆ˜ ìˆ˜ìµë¥ ë§Œ ë°˜ì˜

        ìˆ˜í•™ì  ê·¼ê±°:
        - reward_scale = 100 / volatility
        - volatilityê°€ ë‚®ìœ¼ë©´ (0.001) â†’ scale 100,000 (ë¯¼ê°)
        - volatilityê°€ ë†’ìœ¼ë©´ (0.01) â†’ scale 10,000 (ì•ˆì •)
        - í‰ê·  volatility (0.002) â†’ scale 50,000
        """
        if prev_value <= 0:
            return -1000.0  # íŒŒì‚°ë§Œ í˜ë„í‹°

        # í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥ 
        portfolio_return = (new_value - prev_value) / prev_value

        # ğŸ”‘ ì ì‘í˜• ë³´ìƒ ìŠ¤ì¼€ì¼
        # volatilityê°€ ë‚®ì„ìˆ˜ë¡ í° ìŠ¤ì¼€ì¼ (ì‘ì€ ìˆ˜ìµë„ í¬ê²Œ ë³´ìƒ)
        # volatilityê°€ ë†’ì„ìˆ˜ë¡ ì‘ì€ ìŠ¤ì¼€ì¼ (í° ë³€ë™ì„ ì •ê·œí™”)
        reward_scale = 100.0 / max(self.current_volatility, 0.0001)

        # ìŠ¤ì¼€ì¼ ë²”ìœ„ ì œí•œ (ì•ˆì •ì„±)
        reward_scale = np.clip(reward_scale, 5000.0, 100000.0)

        reward = portfolio_return * reward_scale

        # íŒŒì‚° í˜ë„í‹°ë§Œ ìœ ì§€
        if self.balance <= 0:
            reward -= 1000.0

        return reward

    def render(self, mode='human'):
        if mode == 'human':
            portfolio = self._calculate_portfolio_value()
            print(f"Step: {self.current_step}, Portfolio: ${portfolio:.2f}, "
                  f"Position: {self.position:.4f}, PnL: ${self.total_pnl:.2f}, "
                  f"Volatility: {self.current_volatility:.6f}")

    def close(self):
        pass
